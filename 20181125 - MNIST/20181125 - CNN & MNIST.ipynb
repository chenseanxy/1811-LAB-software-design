{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple CNN for MNIST"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports:  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "np.random.seed(2)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import itertools\n",
    "\n",
    "from keras.utils.np_utils import to_categorical # convert to one-hot-encoding\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPool2D\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.callbacks import ReduceLROnPlateau, TensorBoard\n",
    "\n",
    "import tensorflow as tf\n",
    "import os\n",
    "import time\n",
    "import pickle\n",
    "\n",
    "sns.set(style='white', context='notebook', palette='deep')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Working directory:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "working_dir=\"C:/Users/chenx/Desktop/1811_softdesign/20181125 - MNIST/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_csv_path = os.path.join(working_dir, \"train.csv\")\n",
    "test_csv_path = os.path.join(working_dir, \"test.csv\")\n",
    "\n",
    "train = pd.read_csv(train_csv_path)\n",
    "test = pd.read_csv(test_csv_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Separate training data into X,Y:  \n",
    "X: Training Label  \n",
    "Y: Image Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    4684\n",
       "7    4401\n",
       "3    4351\n",
       "9    4188\n",
       "2    4177\n",
       "6    4137\n",
       "0    4132\n",
       "4    4072\n",
       "8    4063\n",
       "5    3795\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "Y_train = train[\"label\"]\n",
    "X_train = train.drop(labels = [\"label\"],axis = 1) \n",
    "\n",
    "# Visualization:\n",
    "g = sns.countplot(Y_train)\n",
    "Y_train.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Checking for nulls:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count       784\n",
       "unique        1\n",
       "top       False\n",
       "freq        784\n",
       "dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.isnull().any().describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count       784\n",
       "unique        1\n",
       "top       False\n",
       "freq        784\n",
       "dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.isnull().any().describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Normalization:\n",
    "  \n",
    "From grayscale 0~255 to 0~1  \n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train / 255.0\n",
    "test = test / 255.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reshaping:\n",
    "From 1D 784 to 28x28x1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAQMAAAEBCAYAAAB8GcDAAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4xLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvDW2N/gAADaBJREFUeJzt3X+IXfWZx/H3GKNRSGyRlolG2z/Up0W0W6yNJNqtGCMtapXUhhiMshor1cU/4o+AKTZRkUUIgaxS7TYhqBFBSQTtltpMFmoMKlJ/Zx+CRoh1okhRMdDExNk/7nc2t23mzHXujzOTvF8gzjnPnHsevpn74XvO/d57+4aGhpCkI+puQNL4YBhIAgwDSYVhIAkwDCQVhoEkwDCQVBgGkgDDQFJhGEgCDANJxZG9PmFEHA2cDQwC+3t9fukwMAmYDryUmXtaPaitMIiIK4FlwGRgVWbe38JhZwN/aue8klpyHvBcq7885jCIiBOBe4CzgD3A8xGxOTPfGuXQQYBHH32U/v7+sZ5e0gh27drFwoULoTzXWtXOzGAOMJCZfwWIiCeAnwIrRjluP0B/fz8zZsxo4/SSRvGlLsPbuYF4An+fPIOAz25pgmonDI4Amj8ZpQ/4or12JNWlnTB4j8Ydy2H9wPvttSOpLu3cM/gj8KuI+BqwG5gHXN+RriT13JhnBpn5F+AOYDPwCrA+M1/sVGOSequtdQaZuR5Y36FeJNXI5ciSAMNAUmEYSAIMA0mFYSAJMAwkFYaBJMAwkFQYBpIAw0BSYRhIAgwDSYVhIAkwDCQVhoEkwDCQVBgGkgDDQFJhGEgCDANJhWEgCajhK9mlXrvgggtGrA0MDFQeu27dusr6okWLxtTTeOTMQBJgGEgqDANJgGEgqTAMJAGGgaTCMJAEuM5Ah4Dzzz+/sr5ly5YRa319fZXHjlY/lLQVBhGxGfg68HnZ9fPMfKHtriT13JjDICL6gNOAb2Tmvs61JKkO7dwziPL/P0TEqxFxUycaklSPdsLgq8Am4HLgAuCGiLiwI11J6rkxXyZk5lZg6/B2RPwW+DHwbAf6ktRjY54ZRMS5EdH8drA+DtxIlDTBtPNqwleAFRExC5gMXA3c0JGuJPVcO5cJT0fETODPwCTg/nLpIHXU3XffXVnfurX6z27fvpFf7Jo/f37lsfPmzausH0raWmeQmb8EftmhXiTVyOXIkgDDQFJhGEgCDANJhWEgCfAtzBoHNm7cWFm/5557Kut79+6trJ955pkj1h566KHKY4899tjK+qHEmYEkwDCQVBgGkgDDQFJhGEgCDANJhWEgCXCdgXpk586dI9aWL19eeeyePXsq68cff3xl/a677hqxNnXq1MpjDyfODCQBhoGkwjCQBBgGkgrDQBJgGEgqDANJgOsM1CEvvvhiZX3x4sUj1l5//fW2zr169erK+iWXXNLW4x8unBlIAgwDSYVhIAkwDCQVhoEkwDCQVBgGkgDXGahFDz/8cGV90aJFlfW+vr4Ra8cdd1zlsRdeeGFl/aKLLqqsqzUthUFETAOeBy7OzHcjYg6wEjgGeDwzl3WxR0k9MOplQkTMBJ4DTivbxwBrgJ8A3wbOjogfdbNJSd3Xyj2DxcCNwPtl+/vA9szckZn7gEeAK7rUn6QeGfUyITOvA4iI4V0nAINNvzIIzOh4Z5J6aiyvJhwBDDVt9wFfdKYdSXUZSxi8B0xv2u7nwCWEpAlqLC8tvgBERJwC7ACupHFDUdIE9qXDIDP/FhHXAE8CU4DfAU90uC/12AcffFBZv++++7p27ssuu6yyvnbt2q6dWwe0HAaZ+c2mnzcB3+lGQ5Lq4XJkSYBhIKkwDCQBhoGkwjCQBPgW5sPGxx9/XFmfO3duZf2NN95o6/zTpk0bsXbppZe29djqDGcGkgDDQFJhGEgCDANJhWEgCTAMJBWGgSTAdQaHjd27d1fW2/1a9NHs3LlzxNrUqVO7em61xpmBJMAwkFQYBpIAw0BSYRhIAgwDSYVhIAlwncEh5aOPPhqxdvHFF1ceOzQ0VFkfzTnnnFNZP+qoo9p6fHWfMwNJgGEgqTAMJAGGgaTCMJAEGAaSCsNAEuA6g0PKTTfdNGLt1VdfrTy2r6+vsj5r1qzK+qZNmyrrRx99dGVd9Ws5DCJiGvA8cHFmvhsRa4FzgeFPzViemRu60KOkHmgpDCJiJvAb4LSm3d8DfpCZg91oTFJvtXrPYDFwI/A+QEQcC5wMrImI1yJieUR4/0GawFp6AmfmdZn5p6Zd/cAA8G/AOcB5wLWdb09Sr4zpBmJmvgNcPrwdEauBRTQuJSRNQGOa2kfEGRExr2lXH/B5Z1qSVIexvrTYB6yKiAHgM+B6YF3HupLUc2O9THgtIu4FtgCTgScz87GOdqZ/UvV5BQBvv/32mB97tM8bWLp0aWXddQQT35cKg8z8ZtPPDwAPdLohSfXw5UBJgGEgqTAMJAGGgaTCMJAE+BbmceXDDz+srC9YsKCy/vLLL49YmzJlSuWxDz74YGV9tI9a18TnzEASYBhIKgwDSYBhIKkwDCQBhoGkwjCQBLjOYFzZsKH6w6U3b9485seeOXNmZf2qq64a82Pr0ODMQBJgGEgqDANJgGEgqTAMJAGGgaTCMJAEuM6gpx57rPrT5G+//fa2Hn/27Nkj1tavX9/WY+vQ58xAEmAYSCoMA0mAYSCpMAwkAYaBpMIwkAS0uM4gIu4EflY2n8nM2yJiDrASOAZ4PDOXdanHCeOTTz6prC9bVj1En376aVvnX7JkyYi16dOnt/XYOvSNOjMoT/q5wHeBfwHOiogFwBrgJ8C3gbMj4kfdbFRSd7VymTAILMnMvZn5ObANOA3Ynpk7MnMf8AhwRRf7lNRlo14mZOabwz9HxKk0LhdW0wiJYYPAjI53J6lnWr6BGBGnA88CtwLvAENN5T7gi862JqmXWgqDiJgNbAKWZuY64D2g+Y5UP/B+59uT1CujXiZExEnARmB+Zg6U3S80SnEKsAO4ksYNRUkTVCsvLd4CTAFWRsTwvl8D1wBPltrvgCe60N+E8tRTT1XWd+zY0dXzt/vSpA5vrdxAvBm4eYTydzrbjqS6uAJREmAYSCoMA0mAYSCpMAwkAYaBpMKPSu+gyZMnV9YnTZpUWd+/f39l/cgjq/+5tm/fXlmXqjgzkAQYBpIKw0ASYBhIKgwDSYBhIKkwDCQBrjPoqAULFlTWV6xYUVkfbZ3BHXfcUVm/+uqrK+tSFWcGkgDDQFJhGEgCDANJhWEgCTAMJBWGgSTAdQY9tW3btrpbkEbkzEASYBhIKgwDSYBhIKkwDCQBhoGkwjCQBLS4ziAi7gR+VjafyczbImItcC6wu+xfnpkbutCjpB4YNQwiYg4wF/guMAT8PiIuB74H/CAzB7vboqReaGVmMAgsycy9ABGxDTi5/LcmIk4ENtCYGXzRtU4lddWoYZCZbw7/HBGn0rhcOA/4IfAL4BPgaeBa4Ddd6VJS17X83oSIOB14Brg1MxO4vKm2GliEYSBNWC29mhARs4FNwNLMXBcRZ0TEvKZf6QM+70aDknqjlRuIJwEbgfmZOVB29wGrImIA+Ay4HljXtS4ldV0rlwm3AFOAlRExvO/XwL3AFmAy8GRmPtaVDiX1RCs3EG8Gbh6h/EBn25FUF1cgSgIMA0mFYSAJMAwkFYaBJMAwkFQYBpIAw0BSYRhIAgwDSYVhIAkwDCQVhoEkoJ5vYZ4EsGvXrhpOLR36mp5bk77McXWEwXSAhQsX1nBq6bAyHXi71V+uIwxeovGBqoPA/hrOLx3qJtEIgpe+zEF9Q0ND3WlH0oTiDURJgGEgqTAMJAGGgaTCMJAEGAaSCsNAElDPoqP/FxFXAstofCvTqsy8v85+mkXEZuDrHPgOyZ9n5gs1tkRETAOeBy7OzHcjYg6wEjgGeDwzl42TvtYC5wK7y68sz8wNNfR1J41vDQd4JjNvG0djdrDeah232hYdRcSJwHPAWcAeGn9MCzLzrVoaahIRfcB7wDcyc1/d/QBExEwa33L9LeA04AMggX8FdtL4huxVmfnfdfZVwuB1YG5mDvayl3/oaw6wHDgfGAJ+D/wX8B/UP2YH6+0/gRXUOG51XibMAQYy86+ZuRt4Avhpjf00G/5SyT9ExKsRcVOt3TQsBm4E3i/b3we2Z+aOEliPAFfU3VdEHAucDKyJiNciYnlE1PF3Nggsycy9mfk5sI1GiI6HMTtYbydT87jVeZlwAo1BGTZI4w98PPgqja+g/3calzD/ExGZmc/W1VBmXgfQ9OW3Bxu/GT1u62B99QMDwC+AT4CngWtpzB562debwz9HxKk0puSrGR9jdrDezgN+SI3jVmcYHEFjijSsD/iipl7+TmZuBbYOb0fEb4EfA7WFwUGMy/HLzHeAy4e3I2I1sIgeh0HT+U+ncTlwK7CPxuxgWK1j1txbZiY1j1udlwnvUd7OXPRzYApcq4g4NyIuaNrVx4EbiePFuBy/iDgjIuY17apt7CJiNo0Z3tLMXMc4GrN/7G08jFudM4M/Ar+KiK/RuHs6D7i+xn6afQVYERGzaFwmXA3cUG9L/+QFICLiFGAHcCWwpt6WgMYf8aqIGAA+o/Fvuq7XTUTEScBGYH5mDpTd42LMRuit9nGrbWaQmX8B7gA2A68A6zPzxbr6aZaZT9OYvv0ZeBlYUy4dxo3M/BtwDfAk8BbwvzRuwtYqM18D7gW20Ojrlcx8rIZWbgGmACsj4pWIeIXGeF1D/WN2sN5mUfO4+XkGkgBXIEoqDANJgGEgqTAMJAGGgaTCMJAEGAaSCsNAEgD/B0djUw8jMaLkAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "X_train = X_train.values.reshape(-1,28,28,1)\n",
    "test = test.values.reshape(-1,28,28,1)\n",
    "\n",
    "g = plt.imshow(X_train[0][:,:,0], cmap=plt.cm.binary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Y_train label to hot vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_train = to_categorical(Y_train, num_classes = 10)\n",
    "\n",
    "Y_train[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Splitting test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_seed = 0\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X_train, Y_train,\n",
    "                                                  test_size=0.1, # 10% used for validation\n",
    "                                                  random_state=random_seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Saving processed data\n",
    "    Using pickle to save processed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "pfile = open(os.path.join(\"X_train.pickle\"), \"wb\")\n",
    "pickle.dump(X_train, pfile)\n",
    "pfile.close()\n",
    "\n",
    "pfile = open(os.path.join(\"X_test.pickle\"), \"wb\")\n",
    "pickle.dump(X_test, pfile)\n",
    "pfile.close()\n",
    "\n",
    "pfile = open(os.path.join(\"Y_train.pickle\"), \"wb\")\n",
    "pickle.dump(Y_train, pfile)\n",
    "pfile.close()\n",
    "\n",
    "pfile = open(os.path.join(\"Y_test.pickle\"), \"wb\")\n",
    "pickle.dump(Y_test, pfile)\n",
    "pfile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "pfile = open(os.path.join(\"X_train.pickle\"), \"rb\")\n",
    "X_train = pickle.load(pfile)\n",
    "pfile.close()\n",
    "\n",
    "pfile = open(os.path.join(\"X_test.pickle\"), \"rb\")\n",
    "X_test = pickle.load(pfile)\n",
    "pfile.close()\n",
    "\n",
    "pfile = open(os.path.join(\"Y_train.pickle\"), \"rb\")\n",
    "Y_train = pickle.load(pfile)\n",
    "pfile.close()\n",
    "\n",
    "pfile = open(os.path.join(\"Y_test.pickle\"), \"rb\")\n",
    "Y_test = pickle.load(pfile)\n",
    "pfile.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Models\n",
    "+ Simple\n",
    "+ Convoluted"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Super simple model\n",
    "     Input Layer\n",
    "     All connected, size 128\n",
    "     All connected, size 128\n",
    "     Output all connected, size 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_model = Sequential()\n",
    "\n",
    "simple_model.add(Flatten())\n",
    "simple_model.add(Dense(128, activation=\"relu\"))\n",
    "simple_model.add(Dense(128, activation=\"relu\"))\n",
    "simple_model.add(Dense(10, activation=\"softmax\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training\n",
    "    Using \"adam\" as optimizer: this is an ordinary optimizer for NNs\n",
    "    \"categorical_crossentropy\" as loss function: this is also ordinary\n",
    "    Epoch: 5, not a very complicated network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_model.compile(optimizer='adam',\n",
    "            loss='categorical_crossentropy',\n",
    "            metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 37800 samples, validate on 4200 samples\n",
      "Epoch 1/30\n",
      "37800/37800 [==============================] - 5s 128us/step - loss: 0.0331 - acc: 0.9892 - val_loss: 0.1288 - val_acc: 0.9671\n",
      "Epoch 2/30\n",
      "37800/37800 [==============================] - 5s 120us/step - loss: 0.0270 - acc: 0.9908 - val_loss: 0.1228 - val_acc: 0.9681\n",
      "Epoch 3/30\n",
      "37800/37800 [==============================] - 4s 118us/step - loss: 0.0248 - acc: 0.9918 - val_loss: 0.1349 - val_acc: 0.9679\n",
      "Epoch 4/30\n",
      "37800/37800 [==============================] - 4s 119us/step - loss: 0.0198 - acc: 0.9935 - val_loss: 0.1520 - val_acc: 0.9662\n",
      "Epoch 5/30\n",
      "37800/37800 [==============================] - 5s 120us/step - loss: 0.0201 - acc: 0.9934 - val_loss: 0.1265 - val_acc: 0.9710\n",
      "Epoch 6/30\n",
      "37800/37800 [==============================] - 4s 119us/step - loss: 0.0136 - acc: 0.9953 - val_loss: 0.1480 - val_acc: 0.9695\n",
      "Epoch 7/30\n",
      "37800/37800 [==============================] - 5s 124us/step - loss: 0.0204 - acc: 0.9934 - val_loss: 0.1460 - val_acc: 0.9700\n",
      "Epoch 8/30\n",
      "37800/37800 [==============================] - 5s 124us/step - loss: 0.0128 - acc: 0.9959 - val_loss: 0.1381 - val_acc: 0.9690\n",
      "Epoch 9/30\n",
      "37800/37800 [==============================] - 5s 122us/step - loss: 0.0114 - acc: 0.9958 - val_loss: 0.1576 - val_acc: 0.9700\n",
      "Epoch 10/30\n",
      "37800/37800 [==============================] - 5s 123us/step - loss: 0.0134 - acc: 0.9956 - val_loss: 0.1379 - val_acc: 0.9740\n",
      "Epoch 11/30\n",
      "37800/37800 [==============================] - 5s 121us/step - loss: 0.0141 - acc: 0.9953 - val_loss: 0.1952 - val_acc: 0.9662\n",
      "Epoch 12/30\n",
      "37800/37800 [==============================] - 5s 123us/step - loss: 0.0112 - acc: 0.9964 - val_loss: 0.1553 - val_acc: 0.9745\n",
      "Epoch 13/30\n",
      "37800/37800 [==============================] - 5s 122us/step - loss: 0.0081 - acc: 0.9976 - val_loss: 0.1456 - val_acc: 0.9743\n",
      "Epoch 14/30\n",
      "37800/37800 [==============================] - 5s 124us/step - loss: 0.0142 - acc: 0.9961 - val_loss: 0.1441 - val_acc: 0.9721\n",
      "Epoch 15/30\n",
      "37800/37800 [==============================] - 5s 123us/step - loss: 0.0109 - acc: 0.9964 - val_loss: 0.1735 - val_acc: 0.9707\n",
      "Epoch 16/30\n",
      "37800/37800 [==============================] - 5s 120us/step - loss: 0.0118 - acc: 0.9966 - val_loss: 0.1829 - val_acc: 0.9695\n",
      "Epoch 17/30\n",
      "37800/37800 [==============================] - 5s 120us/step - loss: 0.0065 - acc: 0.9981 - val_loss: 0.1659 - val_acc: 0.9736\n",
      "Epoch 18/30\n",
      "37800/37800 [==============================] - 5s 124us/step - loss: 0.0094 - acc: 0.9967 - val_loss: 0.1809 - val_acc: 0.9748\n",
      "Epoch 19/30\n",
      "37800/37800 [==============================] - 5s 123us/step - loss: 0.0112 - acc: 0.9963 - val_loss: 0.1726 - val_acc: 0.9738\n",
      "Epoch 20/30\n",
      "37800/37800 [==============================] - 5s 122us/step - loss: 0.0061 - acc: 0.9980 - val_loss: 0.1759 - val_acc: 0.9745\n",
      "Epoch 21/30\n",
      "37800/37800 [==============================] - 5s 122us/step - loss: 0.0088 - acc: 0.9976 - val_loss: 0.1595 - val_acc: 0.9738\n",
      "Epoch 22/30\n",
      "37800/37800 [==============================] - 5s 126us/step - loss: 0.0069 - acc: 0.9978 - val_loss: 0.1988 - val_acc: 0.9736\n",
      "Epoch 23/30\n",
      "37800/37800 [==============================] - 5s 123us/step - loss: 0.0123 - acc: 0.9959 - val_loss: 0.1689 - val_acc: 0.9755\n",
      "Epoch 24/30\n",
      "37800/37800 [==============================] - 5s 126us/step - loss: 0.0048 - acc: 0.9983 - val_loss: 0.1814 - val_acc: 0.9731\n",
      "Epoch 25/30\n",
      "37800/37800 [==============================] - 5s 120us/step - loss: 0.0074 - acc: 0.9978 - val_loss: 0.1982 - val_acc: 0.9721\n",
      "Epoch 26/30\n",
      "37800/37800 [==============================] - 5s 124us/step - loss: 0.0088 - acc: 0.9970 - val_loss: 0.1907 - val_acc: 0.9710\n",
      "Epoch 27/30\n",
      "37800/37800 [==============================] - 5s 123us/step - loss: 0.0091 - acc: 0.9973 - val_loss: 0.2009 - val_acc: 0.9726\n",
      "Epoch 28/30\n",
      "37800/37800 [==============================] - 5s 125us/step - loss: 0.0085 - acc: 0.9973 - val_loss: 0.1722 - val_acc: 0.9757\n",
      "Epoch 29/30\n",
      "37800/37800 [==============================] - 5s 123us/step - loss: 0.0057 - acc: 0.9984 - val_loss: 0.2055 - val_acc: 0.9738\n",
      "Epoch 30/30\n",
      "37800/37800 [==============================] - 5s 122us/step - loss: 0.0089 - acc: 0.9972 - val_loss: 0.1887 - val_acc: 0.9757\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1d854873a58>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "simple_model.fit(X_train, Y_train, \n",
    "                 epochs=30,\n",
    "                validation_data = (X_test,Y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluation\n",
    "     Loss and accuracy is slightly lower than in training:\n",
    "     Not very overfitted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4200/4200 [==============================] - 0s 58us/step\n",
      "0.18869466008650318 0.9757142857142858\n"
     ]
    }
   ],
   "source": [
    "val_loss, val_acc = simple_model.evaluate(X_test, Y_test)\n",
    "print(val_loss, val_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Looking at a random example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = simple_model.predict([X_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "choice = np.random.randint(0,4201)\n",
    "\n",
    "print(np.argmax(predictions[choice]))\n",
    "g = plt.imshow(X_test[choice][:,:,0], cmap=plt.cm.binary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Saving simple_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_model_name = \"mnist-simple-{}.model\".format(int(time.time()))\n",
    "simple_model.save(os.path.join(simple_model_name))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CNN Model:\n",
    "    Convlution size32 x2\n",
    "    Down Sampling by 2x2\n",
    "    Drop Out by 25% probablity\n",
    "    \n",
    "    Convlution size64 x2\n",
    "    Down Sampling by 2x2\n",
    "    Drop Out by 25% probablity\n",
    "    \n",
    "    Flatten layer\n",
    "    All connected size256\n",
    "    Drop Out by 50% probablity\n",
    "    Output all connected size10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_model = Sequential()\n",
    "\n",
    "cnn_model.add(Conv2D(filters = 32,\n",
    "                    kernel_size = (5,5),\n",
    "                    padding = 'Same',\n",
    "                    activation = 'relu',\n",
    "                    input_shape = (28,28,1)))\n",
    "\n",
    "cnn_model.add(Conv2D(filters = 32,\n",
    "                    kernel_size = (5,5),\n",
    "                    padding = 'Same',\n",
    "                    activation = 'relu',\n",
    "                    input_shape = (28,28,1)))\n",
    "\n",
    "cnn_model.add(MaxPool2D(pool_size=(2, 2)))\n",
    "cnn_model.add(Dropout(0.25))\n",
    "\n",
    "\n",
    "cnn_model.add(Conv2D(filters = 64,\n",
    "                    kernel_size = (3, 3),\n",
    "                    padding = 'Same',\n",
    "                    activation = 'relu',\n",
    "                    input_shape = (28,28,1)))\n",
    "\n",
    "cnn_model.add(Conv2D(filters = 64,\n",
    "                    kernel_size = (3, 3),\n",
    "                    padding = 'Same',\n",
    "                    activation = 'relu',\n",
    "                    input_shape = (28,28,1)))\n",
    "\n",
    "cnn_model.add(MaxPool2D(pool_size=(2, 2),\n",
    "                        strides=(2, 2)))\n",
    "cnn_model.add(Dropout(0.25))\n",
    "\n",
    "cnn_model.add(Flatten())\n",
    "cnn_model.add(Dense(256, activation='relu'))\n",
    "cnn_model.add(Dropout(0.5))\n",
    "cnn_model.add(Dense(10, activation='softmax')) # Output Layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Optimizer and loss function\n",
    "* Optimizer:\n",
    "      \"Adam\", because it is easier to type\n",
    "* Loss Function:\n",
    "      categorical_crossentropy as ordinary loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnn_model.compile(optimizer='adam',\n",
    "                loss='categorical_crossentropy',\n",
    "                metrics=['accuracy'])\n",
    "hasattr(cnn_model, 'train_function')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Learning rate reduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate_reduction = ReduceLROnPlateau(monitor='val_acc', \n",
    "                                            patience=3, \n",
    "                                            verbose=1, \n",
    "                                            factor=0.5, \n",
    "                                            min_lr=0.00001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data augmentation\n",
    "    Randomly shift, zoom ,rotate; manipulate the images to minimize overfitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "datagen = ImageDataGenerator(\n",
    "        featurewise_center=False,  # set input mean to 0 over the dataset\n",
    "        samplewise_center=False,  # set each sample mean to 0\n",
    "        featurewise_std_normalization=False,  # divide inputs by std of the dataset\n",
    "        samplewise_std_normalization=False,  # divide each input by its std\n",
    "        zca_whitening=False,  # apply ZCA whitening\n",
    "        rotation_range=10,  # randomly rotate images in the range (degrees, 0 to 180)\n",
    "        zoom_range = 0.1, # Randomly zoom image \n",
    "        width_shift_range=0.1,  # randomly shift images horizontally (fraction of total width)\n",
    "        height_shift_range=0.1,  # randomly shift images vertically (fraction of total height)\n",
    "        horizontal_flip=False,  # randomly flip images\n",
    "        vertical_flip=False)  # randomly flip images\n",
    "\n",
    "datagen.fit(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 16\n",
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Setting up TensorBoard:\n",
    "cnn_model_name = \"mnist-cnn-e%i-b%i-%i\" %(epochs, batch_size,int(time.time()))\n",
    "logd = os.path.join(working_dir, \"logs\", cnn_model_name)\n",
    "tensorboard = TensorBoard(log_dir=logd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/16\n",
      "1181/1181 [==============================] - 12s 10ms/step - loss: 0.3436 - acc: 0.8912 - val_loss: 0.0631 - val_acc: 0.9821\n",
      "Epoch 2/16\n",
      "1181/1181 [==============================] - 12s 10ms/step - loss: 0.1224 - acc: 0.9639 - val_loss: 0.0399 - val_acc: 0.9879\n",
      "Epoch 3/16\n",
      "1181/1181 [==============================] - 11s 10ms/step - loss: 0.0903 - acc: 0.9735 - val_loss: 0.0442 - val_acc: 0.9881\n",
      "Epoch 4/16\n",
      "1181/1181 [==============================] - 11s 10ms/step - loss: 0.0792 - acc: 0.9762 - val_loss: 0.0593 - val_acc: 0.9824\n",
      "Epoch 5/16\n",
      "1181/1181 [==============================] - 11s 10ms/step - loss: 0.0700 - acc: 0.9790 - val_loss: 0.0429 - val_acc: 0.9888\n",
      "Epoch 6/16\n",
      "1181/1181 [==============================] - 11s 10ms/step - loss: 0.0642 - acc: 0.9815 - val_loss: 0.0322 - val_acc: 0.9912\n",
      "Epoch 7/16\n",
      "1181/1181 [==============================] - 11s 10ms/step - loss: 0.0619 - acc: 0.9820 - val_loss: 0.0250 - val_acc: 0.9907\n",
      "Epoch 8/16\n",
      "1181/1181 [==============================] - 11s 10ms/step - loss: 0.0594 - acc: 0.9824 - val_loss: 0.0272 - val_acc: 0.9921\n",
      "Epoch 9/16\n",
      "1181/1181 [==============================] - 11s 10ms/step - loss: 0.0573 - acc: 0.9829 - val_loss: 0.0255 - val_acc: 0.9929\n",
      "Epoch 10/16\n",
      "1181/1181 [==============================] - 11s 10ms/step - loss: 0.0511 - acc: 0.9851 - val_loss: 0.0201 - val_acc: 0.9948\n",
      "Epoch 11/16\n",
      "1181/1181 [==============================] - 11s 10ms/step - loss: 0.0489 - acc: 0.9858 - val_loss: 0.0252 - val_acc: 0.9938\n",
      "Epoch 12/16\n",
      "1181/1181 [==============================] - 11s 10ms/step - loss: 0.0469 - acc: 0.9863 - val_loss: 0.0221 - val_acc: 0.9933\n",
      "Epoch 13/16\n",
      "1181/1181 [==============================] - 11s 10ms/step - loss: 0.0499 - acc: 0.9854 - val_loss: 0.0281 - val_acc: 0.9924\n",
      "\n",
      "Epoch 00013: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "Epoch 14/16\n",
      "1181/1181 [==============================] - 11s 10ms/step - loss: 0.0364 - acc: 0.9894 - val_loss: 0.0195 - val_acc: 0.9943\n",
      "Epoch 15/16\n",
      "1181/1181 [==============================] - 11s 10ms/step - loss: 0.0319 - acc: 0.9910 - val_loss: 0.0187 - val_acc: 0.9948\n",
      "Epoch 16/16\n",
      "1181/1181 [==============================] - 11s 10ms/step - loss: 0.0327 - acc: 0.9905 - val_loss: 0.0187 - val_acc: 0.9945\n",
      "\n",
      "Epoch 00016: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n"
     ]
    }
   ],
   "source": [
    "history = cnn_model.fit_generator(datagen.flow(X_train,Y_train,batch_size=batch_size),\n",
    "                                  epochs = epochs, \n",
    "                                  validation_data = (X_test,Y_test), \n",
    "                                  steps_per_epoch = X_train.shape[0] // batch_size, \n",
    "                                  callbacks = [learning_rate_reduction, tensorboard])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4200/4200 [==============================] - 0s 105us/step\n",
      "0.018718373173953643 0.9945238095238095\n"
     ]
    }
   ],
   "source": [
    "val_loss, val_acc = cnn_model.evaluate(X_test, Y_test)\n",
    "print(val_loss, val_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_model.save(os.path.join(cnn_model_name)+\".model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (tfGPU)",
   "language": "python",
   "name": "tfgpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
