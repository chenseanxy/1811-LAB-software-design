{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple CNN for MNIST"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports:  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "np.random.seed(2)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import itertools\n",
    "\n",
    "from keras.utils.np_utils import to_categorical # convert to one-hot-encoding\n",
    "from keras.models import Sequential, load_model\n",
    "from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPool2D\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.callbacks import ReduceLROnPlateau, TensorBoard\n",
    "\n",
    "import tensorflow as tf\n",
    "import os\n",
    "import time\n",
    "import pickle\n",
    "\n",
    "sns.set(style='white', context='notebook', palette='deep')\n",
    "\n",
    "working_dir=\"C:/Users/chenx/Desktop/1811_softdesign/20181125 - MNIST/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_csv_path = os.path.join(working_dir, \"dataset\",\"train.csv\")\n",
    "test_csv_path = os.path.join(working_dir, \"dataset\", \"test.csv\")\n",
    "\n",
    "train = pd.read_csv(train_csv_path)\n",
    "test = pd.read_csv(test_csv_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Separate training data into X,Y:  \n",
    "X: Training Label  \n",
    "Y: Image Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    4684\n",
       "7    4401\n",
       "3    4351\n",
       "9    4188\n",
       "2    4177\n",
       "6    4137\n",
       "0    4132\n",
       "4    4072\n",
       "8    4063\n",
       "5    3795\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "Y_train = train[\"label\"]\n",
    "X_train = train.drop(labels = [\"label\"],axis = 1) \n",
    "\n",
    "# Visualization:\n",
    "g = sns.countplot(Y_train)\n",
    "Y_train.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Checking for nulls:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count       784\n",
       "unique        1\n",
       "top       False\n",
       "freq        784\n",
       "dtype: object"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.isnull().any().describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count       784\n",
       "unique        1\n",
       "top       False\n",
       "freq        784\n",
       "dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.isnull().any().describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Normalization:\n",
    "  \n",
    "From grayscale 0~255 to 0~1  \n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train / 255.0\n",
    "test = test / 255.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reshaping:\n",
    "From 1D 784 to 28x28x1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "X_train = X_train.values.reshape(-1,28,28,1)\n",
    "test = test.values.reshape(-1,28,28,1)\n",
    "\n",
    "g = plt.imshow(X_train[0][:,:,0], cmap=plt.cm.binary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Y_train label to hot vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_train = to_categorical(Y_train, num_classes = 10)\n",
    "\n",
    "Y_train[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Splitting test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_seed = 0\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X_train, Y_train,\n",
    "                                                  test_size=0.1, # 10% used for validation\n",
    "                                                  random_state=random_seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Saving processed data\n",
    "    Using pickle to save processed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "pfile = open(os.path.join(working_dir, \"pickle\", \"X_train.pickle\"), \"wb\")\n",
    "pickle.dump(X_train, pfile)\n",
    "pfile.close()\n",
    "\n",
    "pfile = open(os.path.join(working_dir, \"pickle\", \"X_test.pickle\"), \"wb\")\n",
    "pickle.dump(X_test, pfile)\n",
    "pfile.close()\n",
    "\n",
    "pfile = open(os.path.join(working_dir, \"pickle\", \"Y_train.pickle\"), \"wb\")\n",
    "pickle.dump(Y_train, pfile)\n",
    "pfile.close()\n",
    "\n",
    "pfile = open(os.path.join(working_dir, \"pickle\", \"Y_test.pickle\"), \"wb\")\n",
    "pickle.dump(Y_test, pfile)\n",
    "pfile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "pfile = open(os.path.join(working_dir, \"pickle\", \"X_train.pickle\"), \"rb\")\n",
    "X_train = pickle.load(pfile)\n",
    "pfile.close()\n",
    "\n",
    "pfile = open(os.path.join(working_dir, \"pickle\", \"X_test.pickle\"), \"rb\")\n",
    "X_test = pickle.load(pfile)\n",
    "pfile.close()\n",
    "\n",
    "pfile = open(os.path.join(working_dir, \"pickle\", \"Y_train.pickle\"), \"rb\")\n",
    "Y_train = pickle.load(pfile)\n",
    "pfile.close()\n",
    "\n",
    "pfile = open(os.path.join(working_dir, \"pickle\", \"Y_test.pickle\"), \"rb\")\n",
    "Y_test = pickle.load(pfile)\n",
    "pfile.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Models\n",
    "+ Simple\n",
    "+ Convoluted"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Super simple model\n",
    "     Input Layer\n",
    "     All connected, size 128\n",
    "     All connected, size 128\n",
    "     Output all connected, size 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_model = Sequential()\n",
    "\n",
    "simple_model.add(Flatten())\n",
    "simple_model.add(Dense(128, activation=\"relu\"))\n",
    "simple_model.add(Dense(128, activation=\"relu\"))\n",
    "simple_model.add(Dense(10, activation=\"softmax\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training\n",
    "    Using \"adam\" as optimizer: this is an ordinary optimizer for NNs\n",
    "    \"categorical_crossentropy\" as loss function: this is also ordinary\n",
    "    Epoch: 5, not a very complicated network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_model.compile(optimizer='adam',\n",
    "            loss='categorical_crossentropy',\n",
    "            metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 37800 samples, validate on 4200 samples\n",
      "Epoch 1/30\n",
      "37800/37800 [==============================] - 4s 100us/step - loss: 0.2776 - acc: 0.9169 - val_loss: 0.1487 - val_acc: 0.9555\n",
      "Epoch 2/30\n",
      "37800/37800 [==============================] - 3s 88us/step - loss: 0.1142 - acc: 0.9646 - val_loss: 0.1187 - val_acc: 0.9640\n",
      "Epoch 3/30\n",
      "37800/37800 [==============================] - 3s 88us/step - loss: 0.0775 - acc: 0.9761 - val_loss: 0.1133 - val_acc: 0.9676\n",
      "Epoch 4/30\n",
      "37800/37800 [==============================] - 3s 89us/step - loss: 0.0587 - acc: 0.9815 - val_loss: 0.1214 - val_acc: 0.9643\n",
      "Epoch 5/30\n",
      "37800/37800 [==============================] - 4s 94us/step - loss: 0.0444 - acc: 0.9859 - val_loss: 0.1832 - val_acc: 0.9545\n",
      "Epoch 6/30\n",
      "37800/37800 [==============================] - 3s 90us/step - loss: 0.0363 - acc: 0.9879 - val_loss: 0.1328 - val_acc: 0.9629\n",
      "Epoch 7/30\n",
      "37800/37800 [==============================] - 3s 91us/step - loss: 0.0294 - acc: 0.9900 - val_loss: 0.1124 - val_acc: 0.9721\n",
      "Epoch 8/30\n",
      "37800/37800 [==============================] - 4s 99us/step - loss: 0.0257 - acc: 0.9912 - val_loss: 0.1489 - val_acc: 0.9652\n",
      "Epoch 9/30\n",
      "37800/37800 [==============================] - 4s 101us/step - loss: 0.0198 - acc: 0.9929 - val_loss: 0.1361 - val_acc: 0.9686\n",
      "Epoch 10/30\n",
      "37800/37800 [==============================] - 4s 102us/step - loss: 0.0187 - acc: 0.9943 - val_loss: 0.1235 - val_acc: 0.9731\n",
      "Epoch 11/30\n",
      "37800/37800 [==============================] - 4s 103us/step - loss: 0.0164 - acc: 0.9943 - val_loss: 0.1497 - val_acc: 0.9702\n",
      "Epoch 12/30\n",
      "37800/37800 [==============================] - 4s 104us/step - loss: 0.0171 - acc: 0.9944 - val_loss: 0.1647 - val_acc: 0.9698\n",
      "Epoch 13/30\n",
      "37800/37800 [==============================] - 4s 111us/step - loss: 0.0144 - acc: 0.9951 - val_loss: 0.1408 - val_acc: 0.9740\n",
      "Epoch 14/30\n",
      "37800/37800 [==============================] - 6s 150us/step - loss: 0.0154 - acc: 0.9948 - val_loss: 0.1362 - val_acc: 0.9714\n",
      "Epoch 15/30\n",
      "37800/37800 [==============================] - 5s 127us/step - loss: 0.0119 - acc: 0.9955 - val_loss: 0.1317 - val_acc: 0.9733\n",
      "Epoch 16/30\n",
      "37800/37800 [==============================] - 4s 117us/step - loss: 0.0093 - acc: 0.9970 - val_loss: 0.1656 - val_acc: 0.9698\n",
      "Epoch 17/30\n",
      "37800/37800 [==============================] - 4s 112us/step - loss: 0.0107 - acc: 0.9963 - val_loss: 0.1389 - val_acc: 0.9729\n",
      "Epoch 18/30\n",
      "37800/37800 [==============================] - 4s 110us/step - loss: 0.0080 - acc: 0.9971 - val_loss: 0.1571 - val_acc: 0.9724\n",
      "Epoch 19/30\n",
      "37800/37800 [==============================] - 4s 102us/step - loss: 0.0125 - acc: 0.9960 - val_loss: 0.1448 - val_acc: 0.9767\n",
      "Epoch 20/30\n",
      "37800/37800 [==============================] - 4s 102us/step - loss: 0.0116 - acc: 0.9963 - val_loss: 0.1447 - val_acc: 0.9767\n",
      "Epoch 21/30\n",
      "37800/37800 [==============================] - 4s 101us/step - loss: 0.0099 - acc: 0.9971 - val_loss: 0.1884 - val_acc: 0.9674\n",
      "Epoch 22/30\n",
      "37800/37800 [==============================] - 4s 101us/step - loss: 0.0096 - acc: 0.9969 - val_loss: 0.1764 - val_acc: 0.9712\n",
      "Epoch 23/30\n",
      "37800/37800 [==============================] - 4s 110us/step - loss: 0.0099 - acc: 0.9971 - val_loss: 0.2004 - val_acc: 0.9688\n",
      "Epoch 24/30\n",
      "37800/37800 [==============================] - 4s 105us/step - loss: 0.0063 - acc: 0.9979 - val_loss: 0.1616 - val_acc: 0.9738\n",
      "Epoch 25/30\n",
      "37800/37800 [==============================] - 4s 103us/step - loss: 0.0087 - acc: 0.9971 - val_loss: 0.1740 - val_acc: 0.9729\n",
      "Epoch 26/30\n",
      "37800/37800 [==============================] - 4s 101us/step - loss: 0.0081 - acc: 0.9976 - val_loss: 0.1600 - val_acc: 0.9743\n",
      "Epoch 27/30\n",
      "37800/37800 [==============================] - 4s 102us/step - loss: 0.0110 - acc: 0.9967 - val_loss: 0.1653 - val_acc: 0.9733\n",
      "Epoch 28/30\n",
      "37800/37800 [==============================] - 4s 102us/step - loss: 0.0073 - acc: 0.9973 - val_loss: 0.1671 - val_acc: 0.9733\n",
      "Epoch 29/30\n",
      "37800/37800 [==============================] - 4s 102us/step - loss: 0.0098 - acc: 0.9972 - val_loss: 0.1600 - val_acc: 0.9748\n",
      "Epoch 30/30\n",
      "37800/37800 [==============================] - 4s 102us/step - loss: 0.0043 - acc: 0.9985 - val_loss: 0.1850 - val_acc: 0.9750\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x20f92d91e80>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "simple_model.fit(X_train, Y_train, \n",
    "                 epochs=30,\n",
    "                validation_data = (X_test,Y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluation\n",
    "     Loss and accuracy is slightly lower than in training:\n",
    "     Not very overfitted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4200/4200 [==============================] - 0s 37us/step\n",
      "0.1850168714397233 0.975\n"
     ]
    }
   ],
   "source": [
    "val_loss, val_acc = simple_model.evaluate(X_test, Y_test)\n",
    "print(val_loss, val_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Looking at a random example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = simple_model.predict([X_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "choice = np.random.randint(0,4201)\n",
    "\n",
    "print(np.argmax(predictions[choice]))\n",
    "g = plt.imshow(X_test[choice][:,:,0], cmap=plt.cm.binary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Saving simple_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_model_name = \"mnist-simple-{}.model\".format(int(time.time()))\n",
    "simple_model.save(os.path.join(working_dir, \"models\", simple_model_name))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CNN Model:\n",
    "    Convlution size32 x2\n",
    "    Down Sampling by 2x2\n",
    "    Drop Out by 25% probablity\n",
    "    \n",
    "    Convlution size64 x2\n",
    "    Down Sampling by 2x2\n",
    "    Drop Out by 25% probablity\n",
    "    \n",
    "    Flatten layer\n",
    "    All connected size256\n",
    "    Drop Out by 50% probablity\n",
    "    Output all connected size10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_model = Sequential()\n",
    "\n",
    "cnn_model.add(Conv2D(filters = 32,\n",
    "                    kernel_size = (5,5),\n",
    "                    padding = 'Same',\n",
    "                    activation = 'relu',\n",
    "                    input_shape = (28,28,1)))\n",
    "\n",
    "cnn_model.add(Conv2D(filters = 32,\n",
    "                    kernel_size = (5,5),\n",
    "                    padding = 'Same',\n",
    "                    activation = 'relu',\n",
    "                    input_shape = (28,28,1)))\n",
    "\n",
    "cnn_model.add(MaxPool2D(pool_size=(2, 2)))\n",
    "cnn_model.add(Dropout(0.25))\n",
    "\n",
    "\n",
    "cnn_model.add(Conv2D(filters = 64,\n",
    "                    kernel_size = (3, 3),\n",
    "                    padding = 'Same',\n",
    "                    activation = 'relu',\n",
    "                    input_shape = (28,28,1)))\n",
    "\n",
    "cnn_model.add(Conv2D(filters = 64,\n",
    "                    kernel_size = (3, 3),\n",
    "                    padding = 'Same',\n",
    "                    activation = 'relu',\n",
    "                    input_shape = (28,28,1)))\n",
    "\n",
    "cnn_model.add(MaxPool2D(pool_size=(2, 2),\n",
    "                        strides=(2, 2)))\n",
    "cnn_model.add(Dropout(0.25))\n",
    "\n",
    "cnn_model.add(Flatten())\n",
    "cnn_model.add(Dense(256, activation='relu'))\n",
    "cnn_model.add(Dropout(0.5))\n",
    "cnn_model.add(Dense(10, activation='softmax')) # Output Layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Optimizer and loss function\n",
    "* Optimizer:\n",
    "      \"Adam\", because it is easier to type\n",
    "* Loss Function:\n",
    "      categorical_crossentropy as ordinary loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnn_model.compile(optimizer='adam',\n",
    "                loss='categorical_crossentropy',\n",
    "                metrics=['accuracy'])\n",
    "hasattr(cnn_model, 'train_function')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Learning rate reduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate_reduction = ReduceLROnPlateau(monitor='val_acc', \n",
    "                                            patience=3, \n",
    "                                            verbose=1, \n",
    "                                            factor=0.5, \n",
    "                                            min_lr=0.00001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data augmentation\n",
    "    Randomly shift, zoom ,rotate; manipulate the images to minimize overfitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "datagen = ImageDataGenerator(\n",
    "        featurewise_center=False,  # set input mean to 0 over the dataset\n",
    "        samplewise_center=False,  # set each sample mean to 0\n",
    "        featurewise_std_normalization=False,  # divide inputs by std of the dataset\n",
    "        samplewise_std_normalization=False,  # divide each input by its std\n",
    "        zca_whitening=False,  # apply ZCA whitening\n",
    "        rotation_range=10,  # randomly rotate images in the range (degrees, 0 to 180)\n",
    "        zoom_range = 0.1, # Randomly zoom image \n",
    "        width_shift_range=0.1,  # randomly shift images horizontally (fraction of total width)\n",
    "        height_shift_range=0.1,  # randomly shift images vertically (fraction of total height)\n",
    "        horizontal_flip=False,  # randomly flip images\n",
    "        vertical_flip=False)  # randomly flip images\n",
    "\n",
    "datagen.fit(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 16\n",
    "batch_size = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Setting up TensorBoard:\n",
    "cnn_model_name = \"mnist-cnn-e%i-b%i-%i\" %(epochs, batch_size,int(time.time()))\n",
    "logd = os.path.join(working_dir, \"logs\", cnn_model_name)\n",
    "tensorboard = TensorBoard(log_dir=logd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/16\n",
      "295/295 [==============================] - 11s 39ms/step - loss: 0.4783 - acc: 0.8462 - val_loss: 0.0795 - val_acc: 0.9745\n",
      "Epoch 2/16\n",
      "295/295 [==============================] - 10s 34ms/step - loss: 0.1572 - acc: 0.9527 - val_loss: 0.0526 - val_acc: 0.9843\n",
      "Epoch 3/16\n",
      "295/295 [==============================] - 10s 34ms/step - loss: 0.1115 - acc: 0.9667 - val_loss: 0.0549 - val_acc: 0.9848 - ETA: 1s - loss: 0.1140 - acc: 0. - ETA: 1s - loss\n",
      "Epoch 4/16\n",
      "295/295 [==============================] - 10s 34ms/step - loss: 0.0911 - acc: 0.9725 - val_loss: 0.0394 - val_acc: 0.9881\n",
      "Epoch 5/16\n",
      "295/295 [==============================] - 10s 34ms/step - loss: 0.0817 - acc: 0.9750 - val_loss: 0.0266 - val_acc: 0.9921\n",
      "Epoch 6/16\n",
      "295/295 [==============================] - 10s 34ms/step - loss: 0.0707 - acc: 0.9789 - val_loss: 0.0240 - val_acc: 0.9929s: 0.0 - ETA: 2s - loss: 0.0707 - acc: 0.9 - ETA: 2s - loss: 0.0704 - ETA: 1s - loss\n",
      "Epoch 7/16\n",
      "295/295 [==============================] - 11s 37ms/step - loss: 0.0618 - acc: 0.9816 - val_loss: 0.0310 - val_acc: 0.9919\n",
      "Epoch 8/16\n",
      "295/295 [==============================] - 14s 49ms/step - loss: 0.0580 - acc: 0.9825 - val_loss: 0.0209 - val_acc: 0.9929\n",
      "Epoch 9/16\n",
      "295/295 [==============================] - 12s 39ms/step - loss: 0.0543 - acc: 0.9843 - val_loss: 0.0241 - val_acc: 0.9933\n",
      "Epoch 10/16\n",
      "295/295 [==============================] - 11s 38ms/step - loss: 0.0531 - acc: 0.9842 - val_loss: 0.0192 - val_acc: 0.9948: 1s - \n",
      "Epoch 11/16\n",
      "295/295 [==============================] - 11s 37ms/step - loss: 0.0492 - acc: 0.9855 - val_loss: 0.0279 - val_acc: 0.9912\n",
      "Epoch 12/16\n",
      "295/295 [==============================] - 13s 43ms/step - loss: 0.0491 - acc: 0.9857 - val_loss: 0.0195 - val_acc: 0.9945\n",
      "Epoch 13/16\n",
      "295/295 [==============================] - 11s 37ms/step - loss: 0.0470 - acc: 0.9863 - val_loss: 0.0229 - val_acc: 0.9924\n",
      "\n",
      "Epoch 00013: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "Epoch 14/16\n",
      "295/295 [==============================] - 11s 36ms/step - loss: 0.0358 - acc: 0.9888 - val_loss: 0.0146 - val_acc: 0.9962\n",
      "Epoch 15/16\n",
      "295/295 [==============================] - 10s 35ms/step - loss: 0.0330 - acc: 0.9902 - val_loss: 0.0169 - val_acc: 0.9950s - ETA:\n",
      "Epoch 16/16\n",
      "295/295 [==============================] - 10s 34ms/step - loss: 0.0311 - acc: 0.9904 - val_loss: 0.0178 - val_acc: 0.9945\n"
     ]
    }
   ],
   "source": [
    "history = cnn_model.fit_generator(datagen.flow(X_train,Y_train,batch_size=batch_size),\n",
    "                                  epochs = epochs, \n",
    "                                  validation_data = (X_test,Y_test), \n",
    "                                  steps_per_epoch = X_train.shape[0] // batch_size, \n",
    "                                  callbacks = [learning_rate_reduction, tensorboard])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4200/4200 [==============================] - 0s 104us/step\n",
      "0.017648950389268413 0.995\n"
     ]
    }
   ],
   "source": [
    "val_loss, val_acc = cnn_model.evaluate(X_test, Y_test)\n",
    "print(val_loss, val_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_model.save(os.path.join(working_dir, \"models\", cnn_model_name)+\".model\")\n",
    "\n",
    "#Pickle-dumping training history\n",
    "pfile = open(os.path.join(working_dir, \"models\", cnn_model_name)+\".history\", \"wb\")\n",
    "pickle.dump(history, pfile)\n",
    "pfile.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading pre-trained model and history\n",
    "load_model_name = \"mnist-cnn-e16-b16-1543156612\"\n",
    "cnn_model = load_model(os.path.join(working_dir, \"models\", load_model_name)+\".model\")\n",
    "\n",
    "#Pickle-loading training history\n",
    "pfile = open(os.path.join(working_dir, \"models\", cnn_model_name)+\".history\", \"rb\")\n",
    "history = pickle.load(pfile)\n",
    "pfile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (tfGPU)",
   "language": "python",
   "name": "tfgpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
